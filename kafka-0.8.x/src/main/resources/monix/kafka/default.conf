kafka {

  # Producer specific settings

  bootstrap.servers = "localhost:9092"
  acks = "1"
  buffer.memory = 33554432
  compression.type = "none"
  retries = 0

  batch.size = 16384
  client.id = ""

  linger.ms = 0
  max.request.size = 1048576

  receive.buffer.bytes = 32768
  send.buffer.bytes = 131072

  timeout.ms = 30000

  block.on.buffer.full = true

  metadata.fetch.timeout.ms	= 60000
  metadata.max.age.ms = 300000

  metric.reporters = ""
  metrics.num.samples = 2
  metrics.sample.window.ms = 30000

  reconnect.backoff.ms = 10
  retry.backoff.ms = 100

  # Consumer specific settings

  group.id = ""
  zookeeper.connect = ""

  consumer.id = null

  socket.timeout.ms	= 30000
  socket.receive.buffer.bytes	= 65536
  fetch.message.max.bytes	= 1048576
  num.consumer.fetchers	= 1
  auto.commit.enable = true
  auto.commit.interval.ms	= 60000
  queued.max.message.chunks	= 2
  rebalance.max.retries	= 4
  fetch.min.bytes = 1
  fetch.wait.max.ms	= 100
  rebalance.backoff.ms = 2000
  refresh.leader.backoff.ms	= 200
  auto.offset.reset = "largest"
  consumer.timeout.ms	= -1
  exclude.internal.topics	= true
  partition.assignment.strategy	= "range"
  zookeeper.session.timeout.ms = 6000
  zookeeper.connection.timeout.ms	= 6000
  zookeeper.sync.time.ms = 2000
  offsets.storage	= "zookeeper"
  offsets.channel.backoff.ms = 1000
  offsets.channel.socket.timeout.ms = 10000
  offsets.commit.max.retries = 5
  dual.commit.enabled	= true

  # Monix specific settings

  # Number of requests that KafkaProducerSink
  # can push in parallel
  monix.producer.sink.parallelism = 100

}